{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "91fb5620-c211-4568-b7fb-7762fb45ca62",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import dlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b45fa7df-c3e9-4bb5-8f15-b7434e662ecd",
   "metadata": {},
   "outputs": [],
   "source": [
    "detector = dlib.get_frontal_face_detector()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c464f1f9-35ad-4c7a-9d22-7e28041460fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "face_dataset = {}\n",
    "# Function to append an array to the value of a given key\n",
    "def append_array(key, value):\n",
    "    if key in face_dataset:\n",
    "        face_dataset[key].append(value)\n",
    "    else:\n",
    "        face_dataset[key] = [value]\n",
    "\n",
    "# Load the pre-trained face recognition model provided by dlib\n",
    "face_recognizer = dlib.face_recognition_model_v1('C:\\\\Users\\\\annan\\Documents\\\\Study\\\\Konda\\\\AIDI Course\\\\CapstoneProjects\\\\CapstoneProject-2\\\\images\\\\dlib_face_recognition_resnet_model_v1.dat')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0993821-b00a-452c-86f2-db6b04d8f82e",
   "metadata": {},
   "outputs": [],
   "source": [
    "persons =['kondal']\n",
    "for person in  persons:\n",
    "    path= 'C:\\\\Users\\\\annan\\\\Documents\\\\Study\\\\AIDI Course\\\\CapstoneProjects\\\\CapstoneProject-2\\\\images\\\\' + person+'\\\\WIN_20230612_04_49_20_Pro.jpg'\n",
    "    image = dlib.load_rgb_image(path)\n",
    "    # Detect faces in the image\n",
    "    faces = dlib.get_frontal_face_detector()(image)\n",
    "    # Iterate over detected faces and compute face encodings\n",
    "    for face in faces:\n",
    "        face_encoding = face_recognizer.compute_face_descriptor(image, face)\n",
    "        append_array(person,face_encoding)\n",
    "\n",
    "print(face_dataset)\n",
    "\n",
    "# Open the default camera\n",
    "video_capture = cv2.VideoCapture(0)\n",
    "\n",
    "while True:\n",
    "    # Read each frame from the camera\n",
    "    ret, frame = video_capture.read()\n",
    "\n",
    "    # Convert the frame to grayscale\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Detect faces in the grayscale frame\n",
    "    faces = detector(gray)\n",
    "\n",
    "    # Iterate over detected faces\n",
    "    for face in faces:\n",
    "        # Get the face encodings for the current face\n",
    "        face_encodings = face_recognizer.compute_face_descriptor(frame, face)\n",
    "\n",
    "        # Compare face encodings with the known face dataset\n",
    "        for label, encodings in face_dataset.items():\n",
    "            for known_encoding in encodings:\n",
    "                # Compare the current face encoding with the known encoding\n",
    "                distance = dlib.distance(face_encodings, known_encoding)\n",
    "\n",
    "                # Set a threshold for face recognition\n",
    "                if distance < 0.6:\n",
    "                    # Draw a rectangle around the face\n",
    "                    (x, y, w, h) = (face.left(), face.top(), face.width(), face.height())\n",
    "                    cv2.rectangle(frame, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
    "\n",
    "                    # Display the recognized label\n",
    "                    cv2.putText(frame, label, (x, y - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.9, (0, 255, 0), 2)\n",
    "\n",
    "    # Display the resulting frame\n",
    "    cv2.imshow('Video', frame)\n",
    "\n",
    "    # Exit the loop if the 'q' key is pressed\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# Release the video capture object and close the windows\n",
    "video_capture.release()\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
