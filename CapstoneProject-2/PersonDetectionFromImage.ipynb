{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "34b695cf-7642-45df-acc1-28b2e728d975",
   "metadata": {},
   "outputs": [],
   "source": [
    "import dlib\n",
    "from glob import glob \n",
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# load the face detector, landmark predictor, and face recognition model\n",
    "face_detector = dlib.get_frontal_face_detector()\n",
    "shape_predictor = dlib.shape_predictor(\"C:\\\\Users\\\\annan\\\\Documents\\\\Study\\\\Konda\\\\AIDI Course\\\\CapstoneProjects\\\\CapstoneProject-2\\\\images\\\\shape_predictor_68_face_landmarks.dat\")\n",
    "face_encoder = dlib.face_recognition_model_v1(\"C:\\\\Users\\\\annan\\Documents\\\\Study\\\\Konda\\\\AIDI Course\\\\CapstoneProjects\\\\CapstoneProject-2\\\\images\\\\dlib_face_recognition_resnet_model_v1.dat\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "07c6ea07-eb0f-4c55-b4f4-47778e00b410",
   "metadata": {},
   "outputs": [],
   "source": [
    "VALID_EXTENSIONS = ['.png', '.jpg', '.jpeg']\n",
    "\n",
    "def get_image_paths(root_dir, class_names):\n",
    "    \"\"\" grab the paths to the images in our dataset\"\"\"\n",
    "    image_paths = []\n",
    "    for class_name in class_names:\n",
    "        # grab the paths to the files in the current class directory\n",
    "        class_dir = os.path.sep.join([root_dir, class_name])\n",
    "        class_file_paths = glob(os.path.sep.join([class_dir, '*.*']))\n",
    "\n",
    "        # loop over the file paths in the current class directory\n",
    "        for file_path in class_file_paths:\n",
    "            # extract the file extension of the current file\n",
    "            ext = os.path.splitext(file_path)[1]\n",
    "\n",
    "            # if the file extension is not in the valid extensions list, ignore the file\n",
    "            if ext.lower() not in VALID_EXTENSIONS:\n",
    "                print(\"Skipping file: {}\".format(file_path))\n",
    "                continue\n",
    "\n",
    "            # add the path to the current image to the list of image paths\n",
    "            image_paths.append(file_path)\n",
    "\n",
    "    return image_paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "19955df5-59f9-4ec0-b785-88b0d776678d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def face_rects(image):\n",
    "    # convert the image to grayscale\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    # detect faces in the grayscale image\n",
    "    rects = face_detector(gray, 1)\n",
    "    # return the bounding boxes\n",
    "    return rects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cb64dd34-89f7-4266-9d28-f463c9505cfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def face_landmarks(image):\n",
    "    return [shape_predictor(image, face_rect) for face_rect in face_rects(image)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c78f8825-1673-433d-82ad-9b59aa80ee4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def face_encodings(image):\n",
    "    # compute the facial embeddings for each face \n",
    "    # in the input image. the `compute_face_descriptor` \n",
    "    # function returns a 128-d vector that describes the face in an image\n",
    "    return [np.array(face_encoder.compute_face_descriptor(image, face_landmark)) \n",
    "            for face_landmark in face_landmarks(image)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "88b89093-aa09-4a52-b155-87a0f11ca464",
   "metadata": {},
   "outputs": [],
   "source": [
    "def nb_of_matches(known_encodings, unknown_encoding):\n",
    "    # compute the Euclidean distance between the current face encoding \n",
    "    # and all the face encodings in the database\n",
    "    distances = np.linalg.norm(known_encodings - unknown_encoding, axis=1)\n",
    "    # keep only the distances that are less than the threshold\n",
    "    small_distances = distances <= 0.6\n",
    "    # return the number of matches\n",
    "    return sum(small_distances)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8e7eefe8-6d0d-40b5-9213-fd194991f78c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image processed 1/6\n",
      "Image processed 2/6\n",
      "Image processed 3/6\n",
      "Image processed 4/6\n",
      "Image processed 5/6\n",
      "Image processed 6/6\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import cv2\n",
    "import os\n",
    "\n",
    "\n",
    "root_dir = \"C:\\\\Users\\\\annan\\\\Documents\\\\Study\\\\Konda\\\\AIDI Course\\\\CapstoneProjects\\\\CapstoneProject-2\\\\images\"\n",
    "class_names = os.listdir(root_dir)\n",
    "\n",
    "# get the paths to the images\n",
    "image_paths = get_image_paths(root_dir, class_names)\n",
    "# initialize a dictionary to store the name of each person and the corresponding encodings\n",
    "name_encondings_dict = {}\n",
    "nb_current_image = 1\n",
    "# now we can loop over the image paths, locate the faces, and encode them\n",
    "for image_path in image_paths:\n",
    "    print(f\"Image processed {nb_current_image}/{len(image_paths)}\")\n",
    "    # load the image\n",
    "    image = cv2.imread(image_path)\n",
    "    # get the face embeddings\n",
    "    encodings = face_encodings(image)\n",
    "    # get the name from the image path\n",
    "    name = image_path.split(os.path.sep)[-2]\n",
    "    # get the encodings for the current name\n",
    "    e = name_encondings_dict.get(name, [])\n",
    "    # update the list of encodings for the current name\n",
    "    e.extend(encodings)\n",
    "    # update the list of encodings for the current name\n",
    "    name_encondings_dict[name] = e\n",
    "    nb_current_image += 1\n",
    "with open(\"C:\\\\Users\\\\annan\\\\Documents\\\\Study\\\\Konda\\\\AIDI Course\\\\CapstoneProjects\\\\CapstoneProject-2\\\\pickleFile\\\\encodings.pickle\", \"wb\") as f:\n",
    "    pickle.dump(name_encondings_dict, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "129dc8f4-f094-4f45-aeb0-1f5f8de20328",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import cv2\n",
    "\n",
    "# load the encodings + names dictionary\n",
    "with open(\"C:\\\\Users\\\\annan\\\\Documents\\\\Study\\\\Konda\\\\AIDI Course\\\\CapstoneProjects\\\\CapstoneProject-2\\\\pickleFile\\\\encodings.pickle\", \"rb\") as f:\n",
    "    name_encodings_dict = pickle.load(f)\n",
    "    \n",
    "# import  tkinter as tk\n",
    "# from tkinter import filedialog\n",
    "# root = tk.Tk()\n",
    "# root.withdraw()\n",
    "# file_path = filedialog.askopenfilename()\n",
    "# file_path='C:\\\\Users\\\\annan\\\\Documents\\\\Study\\\\Konda\\\\AIDI Course\\\\CapstoneProjects\\\\CapstoneProject-2\\\\testImaage\\\\WIN_20230615_13_30_39_Pro.jpg'\n",
    "# file_path='C:\\\\Users\\\\annan\\\\Documents\\\\Study\\\\Konda\\\\AIDI Course\\\\CapstoneProjects\\\\CapstoneProject-2\\\\testImaage\\\\WIN_20230612_04_50_31_Pro.jpg'\n",
    "file_path='C:\\\\Users\\\\annan\\\\Documents\\\\Study\\\\Konda\\\\AIDI Course\\\\CapstoneProjects\\\\CapstoneProject-2\\\\testImaage\\\\WhatsApp Image 2023-06-15 at 14.04.26.jpg'\n",
    "# load the input image\n",
    "image = cv2.imread(file_path)\n",
    "# get the 128-d face embeddings for each face in the input image\n",
    "encodings = face_encodings(image)\n",
    "# this list will contain the names of each face detected in the image\n",
    "names = []\n",
    "# ...\n",
    "\n",
    "# loop over the encodings\n",
    "for encoding in encodings:\n",
    "    # initialize a dictionary to store the name of the \n",
    "    # person and the number of times it was matched\n",
    "    counts = {}\n",
    "    # loop over the known encodings\n",
    "    for (name, encodings) in name_encodings_dict.items():\n",
    "        # compute the number of matches between the current encoding and the encodings \n",
    "        # of the known faces and store the number of matches in the dictionary\n",
    "        counts[name] = nb_of_matches(encodings, encoding)\n",
    "    # check if all the number of matches are equal to 0\n",
    "    # if there is no match for any name, then we set the name to \"Unknown\"\n",
    "    if all(count == 0 for count in counts.values()):\n",
    "        name = \"Unknown\"\n",
    "    # otherwise, we get the name with the highest number of matches\n",
    "    else:\n",
    "        name = max(counts, key=counts.get)\n",
    "    \n",
    "    # add the name to the list of names\n",
    "    names.append(name)\n",
    "for rect, name in zip(face_rects(image), names):\n",
    "    # get the bounding box for each face using the `rect` variable\n",
    "    x1, y1, x2, y2 = rect.left(), rect.top(), rect.right(), rect.bottom()\n",
    "    # draw the bounding box of the face along with the name of the person\n",
    "    cv2.rectangle(image, (x1, y1), (x2, y2), (0, 255, 0), 2)\n",
    "    cv2.putText(image, name, (x1, y1 - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.75, (0, 255, 0), 2)\n",
    "    # show the output image\n",
    "    cv2.imshow(\"image\", image)\n",
    "    cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9503de1a-682c-42f4-ab14-f99fcdcdbbb1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdd2949b-4108-415c-80c3-e26caeedce9e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f225074-4fae-419d-ac51-d96df1525354",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0549852-34ca-4216-aa22-208e226401a8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
